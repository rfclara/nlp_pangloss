/mnt2/wisniewski/clara/fa_na/.pixi/envs/default/lib/python3.9/site-packages/torchaudio/functional/_alignment.py
torch.__version__=2.5.1
torchaudio.__version__=2.5.1
Using cuda:0
Audio resampled to 16000 Hz
Prediction: ['hĩ˧di˧qo˥ mɤ˧hwæ˧ɲi˥ mæ˩']
normalized_gold='hĩ˧di˧qo˥|mɤ˧hwæ˧ɲi˥|mæ˩'
tokens=[23, 39, 48, 36, 27, 39, 36, 29, 55, 54, 50, 34, 19, 36, 23, 24, 1, 36, 44, 39, 54, 50, 34, 1, 3]
len(tokens)=25
aligned_tokens=tensor([23, 23, 23, 23, 23, 23, 23, 23, 39, 39, 48, 48, 36, 36, 36, 27, 27, 39,
        36, 36, 36, 36, 36, 29, 29, 55, 55, 54, 50, 50, 34, 34, 19, 36, 36, 36,
        36, 23, 23, 23, 24,  1, 36, 36, 36, 44, 44, 39, 39, 54, 50, 50, 34, 34,
         1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3],
       device='cuda:0', dtype=torch.int32)
len(aligned_tokens)=71
token_spans=[TokenSpan(token=23, start=0, end=8, score=1533529.75), TokenSpan(token=39, start=8, end=10, score=3669613.75), TokenSpan(token=48, start=10, end=12, score=2994622.25), TokenSpan(token=36, start=12, end=15, score=2011954.5), TokenSpan(token=27, start=15, end=17, score=2001062.5), TokenSpan(token=39, start=17, end=18, score=7874512.5), TokenSpan(token=36, start=18, end=23, score=657882.5625), TokenSpan(token=29, start=23, end=25, score=6058166.5), TokenSpan(token=55, start=25, end=27, score=3526790.0), TokenSpan(token=54, start=27, end=28, score=9823803.0), TokenSpan(token=50, start=28, end=30, score=960933.0), TokenSpan(token=34, start=30, end=32, score=714110.375), TokenSpan(token=19, start=32, end=33, score=13494455.0), TokenSpan(token=36, start=33, end=37, score=2153353.0), TokenSpan(token=23, start=37, end=40, score=4034345.5), TokenSpan(token=24, start=40, end=41, score=4668124.5), TokenSpan(token=1, start=41, end=42, score=5448058.0), TokenSpan(token=36, start=42, end=45, score=516684.4375), TokenSpan(token=44, start=45, end=47, score=3626772.75), TokenSpan(token=39, start=47, end=49, score=3163695.25), TokenSpan(token=54, start=49, end=50, score=3039223.5), TokenSpan(token=50, start=50, end=52, score=2416195.0), TokenSpan(token=34, start=52, end=54, score=2846884.5), TokenSpan(token=1, start=54, end=55, score=3163286.5), TokenSpan(token=3, start=55, end=71, score=155414.609375)]
word_spans=[[TokenSpan(token=23, start=0, end=8, score=1533529.75), TokenSpan(token=39, start=8, end=10, score=3669613.75), TokenSpan(token=48, start=10, end=12, score=2994622.25), TokenSpan(token=36, start=12, end=15, score=2011954.5), TokenSpan(token=27, start=15, end=17, score=2001062.5), TokenSpan(token=39, start=17, end=18, score=7874512.5), TokenSpan(token=36, start=18, end=23, score=657882.5625), TokenSpan(token=29, start=23, end=25, score=6058166.5), TokenSpan(token=55, start=25, end=27, score=3526790.0), TokenSpan(token=54, start=27, end=28, score=9823803.0)], [TokenSpan(token=34, start=30, end=32, score=714110.375), TokenSpan(token=19, start=32, end=33, score=13494455.0), TokenSpan(token=36, start=33, end=37, score=2153353.0), TokenSpan(token=23, start=37, end=40, score=4034345.5), TokenSpan(token=24, start=40, end=41, score=4668124.5), TokenSpan(token=1, start=41, end=42, score=5448058.0), TokenSpan(token=36, start=42, end=45, score=516684.4375), TokenSpan(token=44, start=45, end=47, score=3626772.75), TokenSpan(token=39, start=47, end=49, score=3163695.25), TokenSpan(token=54, start=49, end=50, score=3039223.5)], [TokenSpan(token=34, start=52, end=54, score=2846884.5), TokenSpan(token=1, start=54, end=55, score=3163286.5), TokenSpan(token=3, start=55, end=71, score=155414.609375)]]
Saved 0.00_0.56.wav for word 'h i ̃ ˧ d i ˧ q o ˥' from 0.00s to 0.56s.
Saved 0.60_1.00.wav for word 'm ɤ ˧ h w æ ˧ ɲ i ˥' from 0.60s to 1.00s.
Saved 1.04_1.42.wav for word 'm æ ˩' from 1.04s to 1.42s.
{'training': False, '_parameters': {}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {'wav2vec2': Wav2Vec2Model(
  (feature_extractor): Wav2Vec2FeatureEncoder(
    (conv_layers): ModuleList(
      (0): Wav2Vec2LayerNormConvLayer(
        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))
        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (activation): GELUActivation()
      )
      (1-4): 4 x Wav2Vec2LayerNormConvLayer(
        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))
        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (activation): GELUActivation()
      )
      (5-6): 2 x Wav2Vec2LayerNormConvLayer(
        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))
        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (activation): GELUActivation()
      )
    )
  )
  (feature_projection): Wav2Vec2FeatureProjection(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (projection): Linear(in_features=512, out_features=1024, bias=True)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (encoder): Wav2Vec2EncoderStableLayerNorm(
    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(
      (conv): ParametrizedConv1d(
        1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _WeightNorm()
          )
        )
      )
      (padding): Wav2Vec2SamePadLayer()
      (activation): GELUActivation()
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (layers): ModuleList(
      (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(
        (attention): Wav2Vec2SdpaAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (feed_forward): Wav2Vec2FeedForward(
          (intermediate_dropout): Dropout(p=0.0, inplace=False)
          (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
          (intermediate_act_fn): GELUActivation()
          (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
          (output_dropout): Dropout(p=0.1, inplace=False)
        )
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
), 'dropout': Dropout(p=0.0, inplace=False), 'lm_head': Linear(in_features=1024, out_features=58, bias=True)}, 'config': Wav2Vec2Config {
  "_attn_implementation_autoset": true,
  "activation_dropout": 0.0,
  "adapter_attn_dim": null,
  "adapter_kernel_size": 3,
  "adapter_stride": 2,
  "add_adapter": false,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "classifier_proj_size": 256,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": true,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": true,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "layer",
  "feat_proj_dropout": 0.0,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_channel_length": 10,
  "mask_channel_min_space": 1,
  "mask_channel_other": 0.0,
  "mask_channel_prob": 0.0,
  "mask_channel_selection": "static",
  "mask_feature_length": 10,
  "mask_feature_min_masks": 0,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_min_masks": 2,
  "mask_time_min_space": 1,
  "mask_time_other": 0.0,
  "mask_time_prob": 0.075,
  "mask_time_selection": "static",
  "model_type": "wav2vec2",
  "num_adapter_layers": 3,
  "num_attention_heads": 16,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 24,
  "num_negatives": 100,
  "output_hidden_size": 1024,
  "pad_token_id": 57,
  "proj_codevector_dim": 256,
  "tdnn_dilation": [
    1,
    2,
    3,
    1,
    1
  ],
  "tdnn_dim": [
    512,
    512,
    512,
    512,
    1500
  ],
  "tdnn_kernel": [
    5,
    3,
    3,
    1,
    1
  ],
  "torch_dtype": "float32",
  "transformers_version": "4.50.0",
  "use_weighted_layer_sum": false,
  "vocab_size": 58,
  "xvector_output_dim": 512
}
, 'loss_type': None, 'name_or_path': '/mnt2/wisniewski/clara/2023/models/Na_best_model', 'warnings_issued': {}, 'generation_config': None, '_keep_in_fp32_modules': None, '_no_split_modules': [], 'target_lang': None, '_tp_plan': {}, '_is_hf_initialized': True}
